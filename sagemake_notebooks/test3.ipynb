{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ccfc2-4f9d-4271-8f62-0e30a59fa1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless\n",
    "!pip install opencv-python --no-binary :all: --compile\n",
    "!pip install python-xlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27374f95-f3cb-4788-ad60-0718d0874401",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df56b67-d03b-4e79-be95-877399022b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install --upgrade autogluon\n",
    "!pip install pandas==1.5.3 pytorch-lightning==1.9.5 scikit-learn==1.3.0 torch==1.13.1 torchmetrics==0.11.4 torchvision==0.14.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7339ea2c-8c2a-4ff9-be62-c9ae69c303fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from skimage.filters import threshold_otsu\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import tempfile\n",
    "import math\n",
    "import logging\n",
    "import shutil\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Average\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c050d551-ee5c-4cae-9f03-dd0a9fef8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_preprocess(file_content):\n",
    "    # Load the image from file content\n",
    "    image = cv2.imdecode(np.frombuffer(file_content, np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Apply contrast stretching\n",
    "    p2, p98 = np.percentile(image, (2, 98))\n",
    "    image_stretched = np.interp(image, (p2, p98), (0, 255)).astype(np.uint8)\n",
    "    \n",
    "    return image_stretched\n",
    "\n",
    "def segment_teeth(image):\n",
    "    # Apply Otsu's thresholding\n",
    "    thresh = threshold_otsu(image)\n",
    "    binary = image > thresh\n",
    "\n",
    "    # Label connected regions\n",
    "    labels = measure.label(binary)\n",
    "\n",
    "    # Filter regions based on properties (size, shape, etc.)\n",
    "    properties = measure.regionprops(labels)\n",
    "    teeth_regions = [prop for prop in properties if prop.area > 1000 and prop.eccentricity < 0.9]\n",
    "\n",
    "    # Create a mask for teeth\n",
    "    teeth_mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    for region in teeth_regions:\n",
    "        teeth_mask[labels == region.label] = 255\n",
    "\n",
    "    return teeth_mask\n",
    "\n",
    "def create_enhanced_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def process_images(input_bucket, input_prefix, output_bucket, output_prefix):\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # List objects in the input bucket with the specified prefix\n",
    "    response = s3.list_objects_v2(Bucket=input_bucket, Prefix=input_prefix)\n",
    "\n",
    "    # Iterate over the objects in the bucket\n",
    "    for obj in response.get('Contents', []):\n",
    "        object_key = obj['Key']\n",
    "\n",
    "        if object_key.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Download the image from S3\n",
    "            file_obj = s3.get_object(Bucket=input_bucket, Key=object_key)\n",
    "            file_content = file_obj['Body'].read()\n",
    "\n",
    "            # Load and preprocess the image\n",
    "            preprocessed_image = load_and_preprocess(file_content)\n",
    "\n",
    "            # Segment teeth\n",
    "            teeth_mask = segment_teeth(preprocessed_image)\n",
    "\n",
    "            # Apply the mask to the original image\n",
    "            segmented_image = cv2.bitwise_and(preprocessed_image, preprocessed_image, mask=teeth_mask)\n",
    "\n",
    "            # Save the segmented image to the output bucket\n",
    "            output_key = f\"{output_prefix}segmented_{object_key.split('/')[-1]}\"\n",
    "            s3.put_object(Bucket=output_bucket, Key=output_key, Body=cv2.imencode('.png', segmented_image)[1].tobytes())\n",
    "\n",
    "            print(f\"Processed and saved: {output_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60aa218e-e80b-4b2c-b864-6c0791bac058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def download_s3_folder(train_bucket, train_prefix, local_dir):\n",
    "    \"\"\"\n",
    "    Download a folder from S3 to a local directory.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    downloaded_files = 0\n",
    "    for result in paginator.paginate(Bucket=train_bucket, Prefix=train_prefix):\n",
    "        for obj in result.get('Contents', []):\n",
    "            key = obj['Key']\n",
    "            if not key.endswith('/'):  # Ignore empty directories\n",
    "                relative_path = os.path.relpath(key, train_prefix)\n",
    "                local_file_path = os.path.join(local_dir, relative_path)\n",
    "                os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "                s3.download_file(train_bucket, key, local_file_path)\n",
    "                downloaded_files += 1\n",
    "                logger.info(f\"Downloaded: {local_file_path}\")\n",
    "    \n",
    "    logger.info(f\"Downloaded {downloaded_files} files from S3\")\n",
    "    if downloaded_files == 0:\n",
    "        raise ValueError(f\"No files found in S3 bucket {train_bucket} with prefix {train_prefix}\")\n",
    "\n",
    "def organize_files(local_dir):\n",
    "    \"\"\"\n",
    "    Organize files into class directories based on their names.\n",
    "    \"\"\"\n",
    "    data_dir = set()\n",
    "   for root, _, files in os.walk(local_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                # Extract class name from file name (adjust this based on your file naming convention)\n",
    "               files_name = file.split('_')[0]  # Assuming class name is the first part of the file name\n",
    "                data_dir = os.path.join(local_dir, files_name)\n",
    "                os.makedirs(data_dir, exist_ok=True)\n",
    "                shutil.move(os.path.join(root, file), os.path.join(data_dir, file))\n",
    "                data_dirs.add(class_name)\n",
    "    \n",
    "    logger.info(f\"Organized files into class directories: {class_dirs}\")\n",
    "    return list(data_dirs)\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "def create_data_generators(data_dir, img_height=128, img_width=128, batch_size=10):\n",
    "    # List all image files\n",
    "    image_files = [f for f in os.listdir(data_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Get class labels\n",
    "    labels = [f.split('_')[0] for f in image_files]  # based on file naming convention\n",
    "    \n",
    "    # Get unique classes\n",
    "    classes = sorted(list(set(labels)))\n",
    "    num_classes = len(classes)\n",
    "    \n",
    "    # Create a mapping of class names to indices\n",
    "    class_to_index = {cls: idx for idx, cls in enumerate(classes)}\n",
    "    \n",
    "    # Convert labels to indices\n",
    "    label_indices = [class_to_index[label] for label in labels]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Further split train+val into train and validation sets\n",
    "    train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "        image_files, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create data generators\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.2        \n",
    "    )\n",
    "\n",
    "    val_test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.2       \n",
    "    )\n",
    "\n",
    "    # Create generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        classes=classes,\n",
    "        shuffle=True,\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "\n",
    "    validation_generator = val_test_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        classes=classes,\n",
    "        shuffle=False,\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator, num_classes\n",
    "\n",
    "def train_model(train_bucket, train_prefix, model_output_path):\n",
    "    # Create a temporary local directory for the S3 data\n",
    "    with tempfile.TemporaryDirectory() as local_data_dir:\n",
    "        try:\n",
    "            # Download the data from S3 to the local directory\n",
    "            download_s3_folder(train_bucket, train_prefix, local_data_dir)\n",
    "\n",
    "            # Create data generators\n",
    "            train_generator, validation_generator, num_classes = create_data_generators(local_data_dir)\n",
    "\n",
    "            # Create the model\n",
    "            model = create_enhanced_model((128, 128, 1), num_classes)\n",
    "\n",
    "            # Define callbacks\n",
    "            lr_scheduler = LearningRateScheduler(step_decay)\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "            # Calculate steps_per_epoch and validation_steps\n",
    "            steps_per_epoch = math.ceil(train_generator.samples / train_generator.batch_size)\n",
    "            validation_steps = math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                train_generator,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=validation_steps,\n",
    "                epochs=50,  # Increased epochs, early stopping will prevent overfitting\n",
    "                callbacks=[lr_scheduler, early_stopping]\n",
    "            )\n",
    "\n",
    "            # Evaluate the model on the test set\n",
    "            test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "            print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "            # Save the model\n",
    "            with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as temp_model_file:\n",
    "                model.save(temp_model_file.name)\n",
    "                \n",
    "                # Upload the model to S3\n",
    "                s3 = boto3.client('s3')\n",
    "                s3.upload_file(temp_model_file.name, train_bucket, model_output_path)\n",
    "                print(f\"Model saved to s3://{train_bucket}/{model_output_path}\")\n",
    "\n",
    "            # Get validation data for metrics calculation\n",
    "            validation_data = next(validation_generator)\n",
    "            validation_images, validation_labels = validation_data[0], validation_data[1]\n",
    "\n",
    "           \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during model training: {str(e)}\")\n",
    "            raise\n",
    "    return model, validation_images, validation_labels, history\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a6563a7-edb9-444c-9c5f-b8bdd34b3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_images(input_bucket, input_prefix, model_output_path, classification_output_file):\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # Download the trained model from S3 to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as temp_model_file:\n",
    "        s3.download_fileobj(input_bucket, model_output_path, temp_model_file)\n",
    "        temp_model_file.flush()\n",
    "        \n",
    "        # Load the model from the temporary file\n",
    "        model = load_model(temp_model_file.name)\n",
    "\n",
    "    # Remove the temporary file\n",
    "    os.unlink(temp_model_file.name)\n",
    "\n",
    "    # Prepare a list to store results\n",
    "    results = []\n",
    "\n",
    "    # List objects in the input bucket with the specified prefix\n",
    "    response = s3.list_objects_v2(Bucket=input_bucket, Prefix=input_prefix)\n",
    "\n",
    "    # Iterate over the objects in the bucket\n",
    "    for obj in response.get('Contents', []):\n",
    "        object_key = obj['Key']\n",
    "\n",
    "        if object_key.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Download the image from S3\n",
    "            file_obj = s3.get_object(Bucket=input_bucket, Key=object_key)\n",
    "            file_content = file_obj['Body'].read()\n",
    "\n",
    "            # Load and preprocess the image\n",
    "            image = load_and_preprocess(file_content)\n",
    "            image = cv2.resize(image, (128, 128))  # Resize to match model input\n",
    "            image = image.reshape((1, 128, 128, 1)) / 255.0  # Normalize\n",
    "\n",
    "            # Predict\n",
    "            prediction = model.predict(image)\n",
    "            class_index = np.argmax(prediction)\n",
    "            class_names = ['normal', 'cavity', 'fracture', 'missing']  # Adjust based on your classes\n",
    "            predicted_class = class_names[class_index]\n",
    "\n",
    "            # Store result\n",
    "            results.append(f\"{object_key}: {predicted_class}\")\n",
    "\n",
    "    # Write results to S3\n",
    "    output_content = '\\n'.join(results).encode('utf-8')\n",
    "    s3.put_object(Bucket=input_bucket, Key=classification_output_file, Body=output_content)\n",
    "\n",
    "    print(f\"Classification results saved to s3://{input_bucket}/{classification_output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abca6d-b39c-4354-a0e8-66d6e63fd3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1234f5db-3ef2-40f9-897f-f1195aad0e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_plot_metrics(model, validation_images, validation_labels, history, output_bucket, output_prefix):\n",
    "    # Make predictions\n",
    "    predictions = model.predict(validation_images)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(validation_labels, axis=1)\n",
    "\n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "    f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "    # Calculate ROC curve and AUC for each class\n",
    "    n_classes = validation_labels.shape[1]\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(validation_labels[:, i], predictions[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = ['blue', 'red', 'green', 'yellow']\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Save the plot\n",
    "    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
    "        plt.savefig(temp_file.name)\n",
    "        s3 = boto3.client('s3')\n",
    "        s3.upload_file(temp_file.name, output_bucket, f\"{output_prefix}roc_curve.png\")\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Save the plot\n",
    "    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
    "        plt.savefig(temp_file.name)\n",
    "        s3.upload_file(temp_file.name, output_bucket, f\"{output_prefix}training_history.png\")\n",
    "\n",
    "    # Save metrics to a file\n",
    "    metrics_content = f\"Accuracy: {accuracy}\\nF1 Score: {f1}\\n\"\n",
    "    for i in range(n_classes):\n",
    "        metrics_content += f\"AUC for class {i}: {roc_auc[i]}\\n\"\n",
    "    \n",
    "    s3.put_object(Bucket=output_bucket, Key=f\"{output_prefix}metrics.txt\", Body=metrics_content.encode('utf-8'))\n",
    "\n",
    "    logger.info(f\"Metrics and plots saved to s3://{output_bucket}/{output_prefix}\")\n",
    "\n",
    "    return accuracy, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a324fc0-b29b-4183-a0e7-d6811ef9aa9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52e9b0b3-eb9f-47ea-823d-8603c55ece5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_1.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_10.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_100.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_102.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_103.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_104.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_105.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_106.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_108.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_109.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_11.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_110.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_111.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_112.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_113.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_114.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_115.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_116.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_117.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_118.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_119.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_12.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_120.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_121.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_122.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_123.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_13.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_14.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_16.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_17.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_18.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_19.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_2.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_21.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_22.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_23.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_24.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_25.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_27.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_28.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_29.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_30.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_31.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_32.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_34.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_35.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_36.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_37.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_38.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_39.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_4.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_40.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_41.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_42.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_43.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_44.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_46.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_47.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_48.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_49.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_5.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_50.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_51.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_52.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_53.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_54.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_55.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_56.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_57.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_58.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_59.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_6.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_61.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_62.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_63.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_64.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_65.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_66.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_67.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_69.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_7.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_70.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_71.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_72.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_73.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_75.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_76.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_77.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_78.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_79.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_8.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_80.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_81.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_82.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_83.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_84.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_86.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_88.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_89.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_9.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_90.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_92.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_94.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_95.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_96.jpg\n",
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_98.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_1.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_10.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/segmented_99.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_100.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_102.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_103.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_104.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_105.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_106.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_108.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_109.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_11.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_110.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_111.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_112.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_113.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_114.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_115.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_116.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_117.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_118.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_119.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_12.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_120.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_121.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_122.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_123.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_13.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_14.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_16.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_17.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_18.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_19.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_2.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_21.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_22.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_23.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_24.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_25.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_27.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_28.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_29.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_30.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_31.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_32.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_34.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_35.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_36.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_37.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_38.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_39.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_4.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_40.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_41.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_42.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_43.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_44.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_46.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_47.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_48.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_49.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_5.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_50.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_51.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_52.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_53.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_54.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_55.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_56.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_57.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_58.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_59.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_6.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_61.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_62.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_63.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_64.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_65.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_66.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_67.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_69.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_7.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_70.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_71.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_72.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_73.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_75.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_76.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_77.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_78.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_79.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_8.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_80.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_81.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_82.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_83.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_84.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_86.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_88.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_89.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_9.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_90.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_92.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_94.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_95.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_96.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_98.jpg\n",
      "INFO:__main__:Downloaded: /tmp/tmpxhjrbo6b/segmented_99.jpg\n",
      "INFO:__main__:Downloaded 107 files from S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 1 classes.\n",
      "Found 0 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during model training: Must provide at least one structure\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must provide at least one structure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 32\u001b[0m\n\u001b[1;32m     27\u001b[0m     classify_images(input_bucket, input_prefix, model_output_path, classification_output_file)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 17\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m process_images(input_bucket, input_prefix, output_bucket, segmented_output_prefix)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m model, validation_images, validation_labels, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_bucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate and plot metrics\u001b[39;00m\n\u001b[1;32m     20\u001b[0m accuracy, f1, roc_auc \u001b[38;5;241m=\u001b[39m calculate_and_plot_metrics(model, validation_images, validation_labels, history, output_bucket, metrics_output_prefix)\n",
      "Cell \u001b[0;32mIn[38], line 146\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(train_bucket, train_prefix, model_output_path)\u001b[0m\n\u001b[1;32m    143\u001b[0m validation_steps \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(validation_generator\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m validation_generator\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Increased epochs, early stopping will prevent overfitting\u001b[39;49;00m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m    156\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(validation_generator)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/tree/optree_impl.py:76\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`func` must be callable. Received: func=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m structures:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust provide at least one structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m     78\u001b[0m     assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Must provide at least one structure"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Define S3 bucket and prefix\n",
    "    input_bucket = 'sagemaker-studio-010526272250-hsf94lgtf6'\n",
    "    output_bucket = input_bucket\n",
    "    input_prefix = 'Test_Dentex_Images/Panoramic_Dental_Xray_Dataset/'\n",
    "    segmented_output_prefix = 'Test_Dentex_Images/Panromic_Xray_Segmented_Dataset/'\n",
    "    train_bucket = input_bucket\n",
    "    train_prefix = segmented_output_prefix\n",
    "    model_output_path = 'Test_Dentex_Images/dental_xray_classifier.h5'\n",
    "    classification_output_file = 'Test_Dentex_Images/classification_results.txt'\n",
    "    metrics_output_prefix = 'Test_Dentex_Images/model_metrics/'\n",
    "\n",
    "    # Process and segment images\n",
    "    process_images(input_bucket, input_prefix, output_bucket, segmented_output_prefix)\n",
    "\n",
    "    # Train the model\n",
    "    model, validation_images, validation_labels, history = train_model(train_bucket, train_prefix, model_output_path)\n",
    "\n",
    "    # Calculate and plot metrics\n",
    "    accuracy, f1, roc_auc = calculate_and_plot_metrics(model, validation_images, validation_labels, history, output_bucket, metrics_output_prefix)\n",
    "\n",
    "    logger.info(f\"Model Accuracy: {accuracy}\")\n",
    "    logger.info(f\"Model F1 Score: {f1}\")\n",
    "    logger.info(f\"Model ROC AUC: {roc_auc}\")\n",
    "\n",
    "    # Classify images\n",
    "    classify_images(input_bucket, input_prefix, model_output_path, classification_output_file)\n",
    "\n",
    "  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dff1fa-0432-4b03-ba6b-b70ed63c797d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1004110-cd54-4631-af39-baa7971b68a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e529d2d-8ce6-47e2-adbd-989f454312ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e22b5-5c8b-42bc-895a-c7597ef93203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bc04d9-529f-4fad-8f37-502a5f5ecc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3d9cc-8aa3-4564-9453-47b6b75e418e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632fbfb-09f1-49eb-bb90-444a8bcbb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51b6ba-0827-422b-a4eb-2efe5831de63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
